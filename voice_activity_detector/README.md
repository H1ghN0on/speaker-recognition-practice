**Часть 2. Обучение детектора речевой активности.**

Детектор речевой активности (VAD, voice activity detector) предназначен для определения присутствия или отсутствия речи в звукозаписи. Входом детектора является обрабатываемый сигнал, а выходом – разметка на «речь» и «не речь». 

Представить разметку детектора речевой активности можно различными способами, например, с использованием rttm-файла, путём визуализации в виде последовательности прямоугольных импульсов переменной длительности, наложенных на осциллограмму обрабатываемого сигнала во временной области и т.п.
В последнем случае речевые участки обычно маркируются уровнем «1», а неречевые участки – уровнем «0».

Файлы расширенной транскрипции с метками времени (RTTM, rich transcription time marked) представляют собой текстовые файлы, в каждой строке которых содержатся разделённые пробелом метаданные привязанных к звукозаписи объектов. Метаданные аннотируют отдельные элементы звукозаписи. Каждая строка rttm-файла представляет аннотацию одного примера объекта. Типы объектов, привязанных к звукозаписи, варьируются по отношению к решаемой задачи. 

Каждая строка rttm-файла содержит 10 полей.
1. Тип сегмента: всегда должен быть SPEAKER
2. ID аудиофайла без расширения (например, rec1_a)
3. Номер канал: всегда 1
4. Начало объекта в секундах от начала записи
5. Длительность объекта в секундах от начала записи
6. Orthography Field -- should always by \< NA \>
7. Speaker Type -- should always be \< NA \>
8. Имя диктора, должно быть уникальным в скопе одного файла
9. Confidence Score -- system confidence (probability) that information is correct; should always be \< NA \>
10. Signal Lookahead Time -- should always be \< NA \>

Пример: 

SPEAKER 00006 1 3.186 1.733 \<NA\> \<NA\> sekibanki \<NA\> \<NA\>

SPEAKER 00006 1 5.253 1.043 \<NA\> \<NA\> yuyuko \<NA\> \<NA\>

SPEAKER 00006 1 6.376 2.007 \<NA\> \<NA\> mima \<NA\> \<NA\>

SPEAKER 00006 1 8.796 0.676 \<NA\> \<NA\> reimu \<NA\> \<NA\>

Если наложить распаршенные данные из RTTM-файла на осцилограмму звукового сигнала, то получится новый график, на котором можно увидеть речевую активность (1 или 0) на отдельных промежутках сигнала.

![Screenshot from 2024-03-10 19-52-43](https://github.com/H1ghN0on/speaker-recognition-practice/assets/65870074/efe1cfeb-e81c-4544-92ad-33cf039a01ea)

**Реализация энергетического детектора речевого детектора на основе модели гауссовой смеси**

1. Разбиение сигнала на переркрывающиеся фреймы

   Отличие перекрывающихся сегментов от обычных, неперекрывающихся, заключается в том, что в первом случае каждый сегмент имеет общие точки с предыдущим сегментом, тогда как во втором случае каждый сегмент анализируется независимо от остальных. Перекрывающиеся сегменты позволяют учитывать эволюцию сигнала во времени и извлекать дополнительные параметры для анализа.

2. Для каждого фрейма вычислить его энергию
3. Выполнить нормализацию и масштабирование энергий сегментов на среднее значение и среднеквадратическое значение энергии, вычисленные по всем сегментам звукозаписи. Полученные среднее значение и среднеквадратическое отклонение будут являться признаками модели гауссовой смеси.

   ![Screenshot from 2024-03-12 23-23-30](https://github.com/H1ghN0on/speaker-recognition-practice/assets/65870074/6d217494-1bde-411d-83b1-05c6a1504545)

4. Обучение модели гауссовой смеси

   Используются три гауссианы, так как по графику энергий у нас примерно получается три нормальных распределения.

   Используются три признака модели, которые будут уточняться: вероятность принадлежности объекта к кластеру, среднее значение и отклонение
   
   Применяем EM-алгоритм, который состоит из двух этапов:
   1. Expectation: рассчитываем скрытый слой - вероятность принадлежности очередного объекта к каждому кластеру
   2. Maximisation: уточняем параметры, на основе рассчитанного скрытого слоя в Expectation.
